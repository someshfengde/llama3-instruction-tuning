INFO:torchtune.utils.logging:Logging /teamspace/studios/this_studio/llama3-8b-hf/original/torchtune_config.yaml to W&B under Files
INFO:torchtune.utils.logging:Model is initialized with precision torch.bfloat16.
INFO:torchtune.utils.logging:Memory Stats after model init:
{'peak_memory_active': 16.572998144, 'peak_memory_alloc': 16.572998144, 'peak_memory_reserved': 16.642998272}
INFO:torchtune.utils.logging:Tokenizer is initialized from file.
INFO:torchtune.utils.logging:Optimizer and loss are initialized.
INFO:torchtune.utils.logging:Loss is initialized.
INFO:torchtune.utils.logging:Dataset and Sampler are initialized.
INFO:torchtune.utils.logging:Learning rate scheduler is initialized.










































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































1|10646|Loss: 0.7629084587097168: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10646/10646 [2:42:11<00:00,  1.09it/s]
INFO:torchtune.utils.logging:Model checkpoint of size 16.06 GB saved to /teamspace/studios/this_studio/llama3-8b-hf/meta_model_0.pt
INFO:torchtune.utils.logging:Adapter checkpoint of size 0.01 GB saved to /teamspace/studios/this_studio/llama3-8b-hf/adapter_0.pt